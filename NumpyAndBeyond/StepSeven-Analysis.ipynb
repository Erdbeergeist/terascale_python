{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "047968c2-ffd6-4372-9e5a-10b422f1bbc1",
    "_uuid": "21fd75c2bd235a740937eebefec9d6f5321ef79f"
   },
   "source": [
    "# Titanic Survivors Analysis\n",
    "**Yacine Haddad, January 2017**\n",
    "\n",
    "![.](http://s2.quickmeme.com/img/56/566939e4d16f26f06f1b648b74270c264240bb66a4d778e53c3f85f84ab3976c.jpg)\n",
    "\n",
    "This notebook is a gentle introduction to data analysis in python step-by-step. Starting from raw data to making prediction model on the Titanic Survivors dataset.\n",
    "\n",
    "On this example, I will cover some basics on pandas, `numpy` array and data-visualisation.\n",
    "I have based this example on few resources that are listed below:\n",
    "* https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n",
    "* https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic\n",
    "* https://www.kaggle.com/jasonm/large-families-not-good-for-survival\n",
    "\n",
    "We start first by setting the environment and loading the dataset from Kaggle website aka [https://www.kaggle.com/c/titanic](https://www.kaggle.com/c/titanic#tutorials). Then explore the data through various visualisation examples that will help us understand the dataset that we are analysing and shape new variables to be used in the predictive model. \n",
    "\n",
    "1. [Dive into data](#Dave into datal)\n",
    "    1. [What story data tell us ?](## What story data tell us ?)\n",
    "    1. [Building new features](## Building new features )\n",
    "    1. [Dealing with missing data](## Dealing with missing data)\n",
    "2. [Making predictive model](#Making predictive model)\n",
    "    1. [What model to choose ?](## What model to choose ?)\n",
    "    2. [Fine tune my model ](## Fine tune my model )\n",
    "3. [Make submission](# Make submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "901a47da-2c50-4404-86be-7b64004cba7d",
    "_uuid": "e8e45301ca821ee9cb3c79381869391f5efd0336"
   },
   "source": [
    "## Dive into data\n",
    "\n",
    "First things first! If you want to be a data scientist, then you need to get some data and dive in it. Kaggle is probably the place to find some data to play with an get started as an analyst. As I am using python, you need to import your exploration kit that will allow you to load, visualise and, most importantly, understand your data. For this tutorial, we ill import numpy and pandas for data manipulation, matplotlib and seaborn for data visualisation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "52867636-8f5e-4afe-b706-a0b3a4d84506",
    "_uuid": "65d14813cfa2a2c92ddafdc78d6a06e6306944a5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "90d02331-f6a5-410c-87a2-adeaf50e86c8",
    "_uuid": "32d83aaf7761829e168a885070a1e2685e92a4d1"
   },
   "source": [
    "The Titanic challenge comes with a training and validation datasets. The first can be used to understand the content of the data and train a model to make a prediction, and then the second can be used to test the model that we will build. \n",
    "\n",
    "``Pandas`` has a built-in function to read and load CSV files and load the data directly into a ``Pandas`` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a904230-9fb1-4987-b233-353dea5ea1f0",
    "_uuid": "7a4e68142734eda08577fb35cfc0c46c2510de7b"
   },
   "outputs": [],
   "source": [
    "# loading the dataset into pandas dataframes\n",
    "data_train = pd.read_csv('data/titanic/train.csv')\n",
    "data_valid = pd.read_csv('data/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1098184d-c823-48ea-a771-d296fda872c4",
    "_uuid": "ad08ae22cc308600da94389f1df21b23a9c8d2fb"
   },
   "source": [
    "> Sometimes, if you can, you can open the data files diretly and look into the data. This will allow you to spot any requirement to read the data, for example in case where the columns are separated by `;` instead of `,`. You can also add columns names in there are not present in the datafile... etc\n",
    "\n",
    "\n",
    "## What story data tell us ?\n",
    "When get hands to data for the first time, it good to know the origin and the context of the data, any information that might come with data is can be useful to build your model. Kaggle page for this dataset (that you can find  [here](http://https://www.kaggle.com/c/titanic/data)), is quite illuminating:\n",
    "\n",
    "| Variable        | Definition           | \n",
    "| ------------- |:-------------:| \n",
    "| survival    | Survival\t0 = No, 1 = Yes | \n",
    "| pclass\t  | Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "| sex\t        | Sex\t|\n",
    "| Age \t      | Age in years\t|\n",
    "| sibsp\t     | # of siblings / spouses aboard the Titanic\t|\n",
    "| parch\t    | # of parents / children aboard the Titanic\t|\n",
    "| ticket \t| Ticket number\t|\n",
    "| fare\t |Passenger fare\t|\n",
    "| cabin\t|Cabin number\t|\n",
    "| embarked|\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton|\n",
    "\n",
    "Ah ha! Now, our data make more sens, isn't it ? It a good practice to see what the data contains, and `describe()` and `dead` are the best `pandas` functions to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f24e5bac-4aac-41f7-8985-ff2831545cda",
    "_uuid": "d601a6e8adb025fc0d7c5af745bfc71654410f9e"
   },
   "outputs": [],
   "source": [
    "# return first 5 rows in the dataframe\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "185c3ac2-bb80-4469-9d4e-be8e6fc280d2",
    "_uuid": "ade949ee7449aec2f3ee99af66bb98186ae1641a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print a dcription of the dataset\n",
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "42a07d468782a75aa9bbafb65bffd7e711010398"
   },
   "source": [
    "From the previous outputs,  we can tell the nature of the data. each row represent a passenger and the columns represent some characteristic that describe the passenger, such as the ticket fare, Age, Name... etc.  We also can tell that the dataset has some missing values, for example the column `Age` has only 714 rows instead of 891, which means that 177 values are missing.  In the column Cabin, we can see that may passenger, with no or unknown cabin. We will see later how to deal with missing data later, and for now let visualise our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c4cf0a2b-da3e-4222-acce-48d88aabd2b3",
    "_uuid": "07391de3d2aff9fcce51fb44b2445b6cbc353ae5"
   },
   "source": [
    "We wanna see, if the parity is respected during the disaster, and therefore can look to the fraction of females and males survived during the disaster.\n",
    "> *Such investigation can be done in two ways, numerical or graphical. But you know probably that saying: A picture is worth a thousand words, so option 2 will be ;) *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f6023f6e-d36b-45b5-8001-9081202116d8",
    "_uuid": "5327efa542422a164ee7da526050a94f500a114d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train.Sex[data_train.Survived==1].hist(bins=2,range=[-0.5,1.5], alpha=0.5, normed=1, label='survived')\n",
    "data_train.Sex[data_train.Survived==0].hist(bins=2,range=[-0.5,1.5], alpha=0.5, normed=1, label='sinked')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "73ec5102-4766-4827-b335-a3676c9941df",
    "_uuid": "cad8a4ac704bc745c7ba58c926e8205a7c5e68d8"
   },
   "source": [
    "Wow! It is clear, in 2012, that rule of \"children and **women** first\" is well respected and this histogram is the proof. more than 65% of the females survived against roughly 30% of males. This is just an example of what a histogram can tell us. \n",
    "> *You can notice here that the historgrams are normalised. The reason is we want to have instead of a simple count, the survival rate for each sex.*\n",
    "\n",
    "Now, let use Seaborn, a wonderful tool that allows us to make similar histograms, by combining 2 or 3 features, in only one line of code. For example, we want to see the survival rate by ticket class for male and females. This can be achieved by calling `barplots` as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "791c1d1f-69d0-442f-9354-30ba034dc7ce",
    "_uuid": "0ddd72e0642369a0f10982204ae4bd6fff6adccb"
   },
   "outputs": [],
   "source": [
    "# how is the fraction of survivors in each class and each class\n",
    "sns.barplot(y=\"Pclass\", x=\"Survived\", hue=\"Sex\",orient='h', data=data_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "192a8e97-d47b-4981-9a7e-6d0e05fc23b2",
    "_uuid": "c3742562b71901ed1fe6157eeec6c37019bcfa1a"
   },
   "source": [
    "The Titanic has collected passengers in 3 different ports. It departed from **Southampton (England)** and made two stops in **Cherbourg (France)** and **Queenstown (Irland)**. We want to see if the port of embarkment has something todo with the survival rate. We did then the same exercise as before, here we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "922dbbcd-66fb-4471-bc19-33b8368bf772",
    "_uuid": "bc6d164fffc96c32399ec236926ad3701f7587de"
   },
   "outputs": [],
   "source": [
    "sns.barplot(y=\"Embarked\", x=\"Survived\", hue=\"Sex\",orient='h', data=data_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2bbfb362-2e06-49f5-9217-6fa388e41824",
    "_uuid": "b130812128f69f9ff20e38cf8a1846a7c052a89c"
   },
   "source": [
    "Obviously, the survival rate seems unbalanced! it seems like the French passengers had more chances of survival. How is this possible? We will try to find out later what secret hides behind this observation.\n",
    "\n",
    "We want to simplify the variable age to include ages tranches. We could then define a function that does that for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "77afa3bb-be3b-43ad-a6b7-ed084e03d470",
    "_uuid": "d98d3d1d9ddd77de5845e1bc0311ce8f852118fa"
   },
   "outputs": [],
   "source": [
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df['Age_category'] = categories\n",
    "    return df\n",
    "\n",
    "data_train = simplify_ages(data_train)\n",
    "data_valid = simplify_ages(data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a8cb5401-81e8-4957-ad3a-76bdae24f4e4",
    "_uuid": "f406c806e74222f3602e001cbbe2022cbbd276a2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,8))\n",
    "sns.barplot(x=\"Survived\", y=\"Age_category\", hue=\"Sex\", orient='h', data=data_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9a21a11a-aae3-44a9-96d3-16465242bd38",
    "_uuid": "fb201d362c457296f94934b8800167a6cd01cb40"
   },
   "source": [
    "Following the same logic, we can also extract information about the cabin, and fill missing data with a \"None\" variable. We could also extract the information about the title of the passenger, this could be helpful when we are going to building a prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bea1fe6d-49d2-46da-84de-b11726da898b",
    "_uuid": "8baa57446ed88c24fd35ce061074442cbfb4a24e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "data_train['Title'] = data_train.Name.apply(lambda x: re.sub(\"(.*, )|(\\\\..*)\", \"\", x))\n",
    "data_train.groupby(['Title','Sex']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0b873762-8d7b-478a-a6a7-aad7ca1e2cf4",
    "_uuid": "a33d1de7d4791e39f97bce2db10202e1ec6c34d6"
   },
   "source": [
    "For our curiosity, Let check some of the personalities on board, and learn some information about them. \n",
    "We can see that on this boat there was a woman with the title \"the Countess\", she is Noël Leslie, Countess of Rothes. Following Wikipedia [https://en.wikipedia.org/wiki/Noël_Leslie,_Countess_of_Rothes](https://en.wikipedia.org/wiki/Noël_Leslie,_Countess_of_Rothes) she was a heroine of the Titanic disaster:\n",
    "> ... famous for taking the tiller of her lifeboat and later helping row the craft to the safety of the rescue ship Carpathia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85560720-8774-4de9-8698-2ec4b32fe720",
    "_uuid": "ba6004e232ce365900f245480dd17d6612bc2c6b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,8))\n",
    "sns.barplot(y=\"Title\", x=\"Survived\", hue=\"Sex\", orient='h', data=data_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "339e69c9-85ea-43e8-9a8b-ff10e3071b34",
    "_uuid": "db59870224b3d417830c37b38e617a01ed5cdaf8"
   },
   "outputs": [],
   "source": [
    "def simplify_titles(df):\n",
    "    df['Title'] = df.Name.apply(lambda x: re.sub(\"(.*, )|(\\\\..*)\", \"\", x))\n",
    "    df['Title'].value_counts()\n",
    "    rare_title = np.array(['Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer'])\n",
    "\n",
    "    # Also reassign mlle, ms, and mme accordingly\n",
    "    df.iloc[df.Title.values == 'Mlle' ,df.columns.get_loc('Title')] = 'Miss' \n",
    "    df.iloc[df.Title.values == 'Ms'   ,df.columns.get_loc('Title')] = 'Miss'\n",
    "    df.iloc[df.Title.values == 'Mme'  ,df.columns.get_loc('Title')] = 'Mrs' \n",
    "    df.iloc[df.Title.isin(rare_title).values ,df.columns.get_loc('Title')] = 'Rare Title'\n",
    "    return df\n",
    "data_train = simplify_titles(data_train)\n",
    "data_valid = simplify_titles(data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "faca8d30-e19a-4c58-8008-318efaeb4254",
    "_uuid": "13ff76b19c500fb29f09413e05a97dce3ecebfe3"
   },
   "outputs": [],
   "source": [
    "sns.barplot(y=\"Title\", x=\"Survived\", orient='h', data=data_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d94f7e5b-1b4a-48b7-9e71-f55c63039133",
    "_uuid": "fa38daa879ef593f475db8a584df33e26ff594a5"
   },
   "outputs": [],
   "source": [
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df['Fare_category'] = categories\n",
    "    return df\n",
    "    \n",
    "def drop_features(df):\n",
    "     return df.drop(['Ticket', 'Name'], axis=1)\n",
    "    \n",
    "    \n",
    "def simplify_embarked(df):\n",
    "    df.Embarked = df.Embarked.fillna('N')\n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = simplify_titles(df)\n",
    "    df = simplify_embarked(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "data_train = transform_features(data_train)\n",
    "data_valid = transform_features(data_valid)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e510b1ba-39cd-45b9-8086-6a4bc9a17c2a",
    "_uuid": "040c7fa1e796e253eb1f2b6954467e73faf0c173"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,8))\n",
    "sns.barplot(y=\"Cabin\", x=\"Survived\", hue=\"Sex\", orient='h', data=data_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "35fe538a-cd10-4567-ac74-e2d53ff45e6c",
    "_uuid": "c56a2c50c62479d9eb6776428a902f16e1e4f087"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,6))\n",
    "sns.barplot(y=\"Fare_category\", x=\"Survived\", hue=\"Sex\",orient='h', data=data_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4a8da65a-732e-4df2-b5d8-81de76245205",
    "_uuid": "c26deb329707409b3a425d43c415463bd0544873"
   },
   "source": [
    "### Does a family size matters ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7ed8fdb5-c04c-4229-ba61-f198da4712f2",
    "_uuid": "fbd2d39e9c66a2c427769dffa6176deb54a50d15"
   },
   "outputs": [],
   "source": [
    "data_train['Fsize'] = data_train.SibSp + data_train.Parch + 1\n",
    "data_valid['Fsize'] = data_valid.SibSp + data_valid.Parch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "278c3f79-0ee8-40b7-b7cc-243d1ce5fea1",
    "_uuid": "d93fec292f24420ba27c6d424da479d3ad195429"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,6))\n",
    "sns.barplot(y=\"Fsize\", x=\"Survived\",orient='h', data=data_train)\n",
    "plt.axvline(0.5, ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "132c8aeb-20c4-4355-94f4-56de512598b4",
    "_uuid": "4c9f3dc80bd0bdea98f8ae95afb5b3a89a22d943"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x=\"Fsize\", hue=\"Survived\", data=data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.Age[data_train.Survived==1].hist(bins=80,range=[0,80], alpha=0.5, normed=1, label='survived')\n",
    "data_train.Age[data_train.Survived==0].hist(bins=80,range=[0,80], alpha=0.5, normed=1, label='sinked')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "057dc9ca-15bd-4bc9-bf83-a05826978b5c",
    "_uuid": "1c09379846fa8069ce58397cc895b9229f4cf671"
   },
   "outputs": [],
   "source": [
    "data_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a847aa59-d15a-4510-8e8e-40326afb1da9",
    "_uuid": "7de653b2a1c85d5898ecfb6e57b6d2fef0399ada"
   },
   "outputs": [],
   "source": [
    "data_valid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "805b8610-3a89-4c00-b8e7-0cf9c992aaba",
    "_uuid": "8741375e09e82019088e68ba9657805795f13cf6"
   },
   "source": [
    "## Making predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "982543dd-5238-489b-8789-65f2058bf945",
    "_uuid": "58566095e522f74e2fad97e6b2ed4e8e833cb4a0"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    str_features = [\n",
    "        'Sex', 'Cabin', 'Embarked', 'Age_category', 'Title', 'Fare_category'\n",
    "    ]\n",
    "    df_combined = pd.concat([df_train[str_features], df_test[str_features]])\n",
    "    \n",
    "    for feature in str_features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "    \n",
    "data_train, data_valid = encode_features(data_train, data_valid)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dd341acc-5ed8-41d9-b15c-e193a4f008a4",
    "_uuid": "d9cfb5961608fe31fe20b73aa88121a0c9b8e0fc"
   },
   "outputs": [],
   "source": [
    "def plot_correlation_map( df ):\n",
    "    corr = df.corr()\n",
    "    _ , ax = plt.subplots( figsize =( 13 , 13 ) )\n",
    "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
    "    _ = sns.heatmap(\n",
    "        corr, \n",
    "        cmap = cmap,\n",
    "        square=True, \n",
    "        cbar_kws={ 'shrink' : .9 }, \n",
    "        ax=ax, \n",
    "        annot = True, \n",
    "        annot_kws = { 'fontsize' : 12 }\n",
    "    )\n",
    "\n",
    "plot_correlation_map( data_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "af431010-5e3b-43b0-8587-55569b401c22",
    "_uuid": "2fc6f7d43d5f656992e14b73cdbc29582323da1c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X_all = data_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y_all = data_train['Survived']\n",
    "\n",
    "num_test = 0.30\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_all, y_all, \n",
    "    test_size=num_test, \n",
    "    random_state=23\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "618bceb4-317d-4b30-85a5-10ef336e02ce",
    "_uuid": "4212d482c6f83a918e293fcba88c6385cdb3a449"
   },
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "50436153-42fc-42f5-8fc9-e6ed7e01993a",
    "_uuid": "f143ac1de05743102009b274cd4485cbfa6826c2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "72b777aa-c2b4-4cf6-891f-99be8916ee71",
    "_uuid": "5f0f410562d40120587e8f4aa298c598654e074a"
   },
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'LogisticRegression'         : LogisticRegression(),\n",
    "    \"RandomForestClassifier\"     : RandomForestClassifier(),\n",
    "    \"GradientBoostingClassifier\" : GradientBoostingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "35a804ba-bfb6-4c82-8bec-e2177b6599fd",
    "_uuid": "b196827446b5d0d93152410e77e48cda884eedaa"
   },
   "outputs": [],
   "source": [
    "for i, clf in clfs.items():\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8adcb512-48d0-4a59-958b-f6acdb287447",
    "_uuid": "d4afb4d888505e049617170fbf11f0a2113bd1c0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "15403600-5a17-4cfb-b6df-d4ee2aaa6829",
    "_uuid": "0611b59003fe0460aa9eb42f56c1f00f246dcb46"
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "for i, clf in clfs.items():\n",
    "    cv_score = cross_validation.cross_val_score(clf,X_all,y_all, cv=5, scoring='accuracy')\n",
    "    print(\"%30s CV Score : Mean - %.3g +\\- %.4g (Min - %.3g, Max - %.3g)\" % (\n",
    "        i, np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "492153a4-8ffe-4965-a822-a8c6e5a3892f",
    "_uuid": "e0074717ebaa3c58cd50e7f254e25702af0a64a1"
   },
   "source": [
    "### Fine tune classifier parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2cbed31a-a0f8-4c4e-b6eb-8416f952b3fd",
    "_uuid": "5b12ccb7bde24ee9cca2afd1c8e7c32152222353",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth'         : range(2,15,2), \n",
    "              'min_samples_split' : np.linspace(0.001,0.01,6),\n",
    "              'min_samples_leaf'  : range(1,10,2),\n",
    "              'subsample'         : [0.7,0.8,0.9],\n",
    "             }\n",
    "\n",
    "grid_obj = GridSearchCV(clfs['GradientBoostingClassifier'], \n",
    "                        parameters, \n",
    "                        cv=5, \n",
    "                        scoring='accuracy',\n",
    "                        n_jobs=-1)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "cv_score = cross_validation.cross_val_score(grid_obj.best_estimator_, \n",
    "                                            X_all, y_all, cv=5, \n",
    "                                            scoring='accuracy')\n",
    "\n",
    "print (grid_obj.best_params_)\n",
    "print (\"CV Score : Mean - %.4g | Std - %.4g | Min - %.4g | Max - %.4g\" % (\n",
    "    np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e2eefdb8-af02-4e1a-bffe-3ee9392c5246",
    "_uuid": "4982e954f89ede9d71701c587c78af90220fffae"
   },
   "source": [
    "Run everything and go make yourself  a tea or a coffe, this might take a while. \n",
    "When the grid search finiches, it returns the parameters that gives better accuracy and for instance, for our case, the best parameters are :\n",
    "```\n",
    "{'max_depth': 2, 'min_samples_leaf': 7, 'min_samples_split': 0.01, 'subsample': 0.8}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f829e638-eb45-493c-9f88-ecfa0b0bdb93",
    "_uuid": "c71625b7b188dd6acb306180bae40961e4015495"
   },
   "source": [
    "## Make predictions and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5fa91233-59b3-4934-8e3c-319ad3e5c4ad",
    "_uuid": "248ab33201820befb0574668c9591654c20421a8"
   },
   "outputs": [],
   "source": [
    "submit = grid_obj.best_estimator_.predict(data_valid.drop(['PassengerId'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ddd881f1-9d7f-45dd-b4c9-eea8e3d80365",
    "_uuid": "5e03feea3740f2e9d11e41d7e713fda395ab7fed"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['PassengerId'] = data_valid['PassengerId']\n",
    "df['Survived'] = submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "092195a7-922a-4d61-91ab-1ae457c6acf3",
    "_uuid": "9a11ee387b5cec2a8883c98997107f11bd7d2646"
   },
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "729e2cc8-9c91-4ead-a825-26ad2e3a6c43",
    "_uuid": "4f54c66cca78bf83499f90aa1b248ec3436e7dfb"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
